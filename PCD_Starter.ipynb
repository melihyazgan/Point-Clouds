{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gWp0tWQxJ3J"
      },
      "source": [
        "# Welcome to the Point Clouds Workshop\n",
        "In this workshop, we're going to combine 3D Machine Learning fonctions to build a pipeline for Clustering(object detection), RANSAC(segmentation), and lane line estimation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhMD341toe7n"
      },
      "source": [
        "## Data & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n8KjwEExLkk"
      },
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from open3d.visualization.draw_plotly import get_plotly_fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMc5V6pxlUTd"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ior0BGFclPBj"
      },
      "outputs": [],
      "source": [
        "point_cloud_files = sorted(glob.glob(\"data/KITTI_PCD/*.pcd\"))\n",
        "idx = 357\n",
        "print(point_cloud_files[idx])   \n",
        "point_cloud =  o3d.io.read_point_cloud(point_cloud_files[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R80l8pBW050d"
      },
      "outputs": [],
      "source": [
        "points = np.asarray(point_cloud.points)\n",
        "colors = np.asarray(point_cloud.colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ6_1WWIo3aE"
      },
      "outputs": [],
      "source": [
        "print(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1baQ1joo44m"
      },
      "outputs": [],
      "source": [
        "print(colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD86DLY4xl13"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "distances = np.linalg.norm(points, axis=1)\n",
        "\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=points[:, 0],\n",
        "    y=points[:, 1],\n",
        "    z=points[:, 2],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=2,\n",
        "        color=distances,  # use distances for color\n",
        "        colorscale='Viridis',  # choose a colorscale\n",
        "        colorbar=dict(title=\"Distance from Origin\"),  # add a colorbar title\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "fig.update_scenes(aspectmode='data')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS_bnkC9vfpv"
      },
      "source": [
        "**Dark Mode?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFw91BB53Spj"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=points[:, 0],\n",
        "    y=points[:, 1],\n",
        "    z=points[:, 2],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=2,\n",
        "        color=distances,  # use distances for color\n",
        "        colorscale='Inferno',  # choose a colorscale Dark Mode:Inferno\n",
        "        colorbar=dict(title=\"Distance from Origin\", bgcolor=\"white\"),  # add a colorbar title\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title=''),\n",
        "        yaxis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title=''),\n",
        "        zaxis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title=''),\n",
        "        aspectmode='data',\n",
        "        camera=dict(\n",
        "            up=dict(x=-0.2, y=0, z=1),\n",
        "            center=dict(x=0.2, y=0, z=0.2),\n",
        "            eye=dict(x=-0.5, y=0, z=0.2))\n",
        "    ),\n",
        "    plot_bgcolor='black',\n",
        "    paper_bgcolor='black',\n",
        "    scene_dragmode='orbit'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ1LYm25wJkQ"
      },
      "source": [
        "**Reflectance**<p>\n",
        "You've seen reflectance before. In this workshop, we're going to go much further in this idea, and actually USE IT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1wXXl9PmHDY"
      },
      "outputs": [],
      "source": [
        "def vis_pcd(point_cloud, save=\"False\", show=True):\n",
        "    fig = get_plotly_fig(point_cloud, width = 800, height = 533, mesh_show_wireframe =False,\n",
        "                            point_sample_factor = 1, front = (1,1,1), lookat =(1,1,1), up=(1,1,1), zoom=1.0)\n",
        "    #fig.update_scenes(aspectmode='data')\n",
        "    fig.update_layout(\n",
        "    scene=dict(\n",
        "        #xaxis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title=''),\n",
        "        xaxis=dict(visible=False,range=[-70,70]),\n",
        "        yaxis=dict(visible=False,range=[-40,40]),\n",
        "        zaxis=dict(visible=False,range = [-5,1]),\n",
        "        aspectmode='manual', aspectratio= dict(x=2, y=1, z=0.1),\n",
        "        camera=dict(\n",
        "            #up=dict(x=-0.2, y=0, z=0.3),\n",
        "            up = dict(x=0.15, y =0, z=1),\n",
        "            center=dict(x=0, y=0, z=0.1),\n",
        "            #eye=dict(x=-0.5, y=0, z=0.2)\n",
        "            eye = dict(x = -0.3, y=0, z=0.2)\n",
        "        )\n",
        "    ),\n",
        "    plot_bgcolor='black',\n",
        "    paper_bgcolor='black',\n",
        "    scene_dragmode='orbit'\n",
        ")\n",
        "    if show == True:\n",
        "        fig.show()\n",
        "\n",
        "    if save != \"False\":\n",
        "        fig.write_image(\"output/\"+save+\"_processed.jpg\", scale=3)\n",
        "\n",
        "    return fig\n",
        "\n",
        "point_cloud = o3d.io.read_point_cloud(point_cloud_files[idx])\n",
        "fig = vis_pcd([point_cloud])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdKyM6Bb0qjU"
      },
      "source": [
        "## How to use Reflectance: Lane Line Detection\n",
        "Because it can detect all these cool things, we can use a LiDAR to detect lane lines in 3D directly. We can use it to detect license plates, traffic signs, and, of course, cars. **Reflectance can be used as a filter**, a threshold, and we could also fuse this with camera outputs to get the best out of it.\n",
        "\n",
        "two techniques to find the lane lines:\n",
        "* Thresholding\n",
        "* ROI\n",
        "They are simple, yet effective (for now).<p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYfr0605v7MV"
      },
      "source": [
        "#### **Thresholding**\n",
        "Let's begin with the idea of a threshold, and only visualize the high reflectance points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM0na17-0sl6"
      },
      "outputs": [],
      "source": [
        "def reflectivity_threshold(pcd, thresh=0.5):\n",
        "    colors = np.asarray(pcd.colors)\n",
        "    reflectivities = colors[:, 0]\n",
        "    # Get the point coordinates\n",
        "    points = np.asarray(pcd.points)\n",
        "    # Create a mask of points that have reflectivity above the threshold\n",
        "    mask = reflectivities > thresh\n",
        "\n",
        "    # Filter points and reflectivities using the mask\n",
        "    filtered_points = points[mask]\n",
        "\n",
        "    # Create a new point cloud with the filtered points\n",
        "    filtered_point_cloud = o3d.geometry.PointCloud()\n",
        "    filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
        "    return filtered_point_cloud\n",
        "\n",
        "#point_cloud = o3d.io.read_point_cloud(point_cloud_files[idx])\n",
        "filtered_point_cloud = reflectivity_threshold(point_cloud, thresh=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQVOOFas1M53"
      },
      "outputs": [],
      "source": [
        "fig = vis_pcd([point_cloud.paint_uniform_color((0.2,0.2,0.2)),filtered_point_cloud])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lfdUxyurLHB"
      },
      "source": [
        "#### **Region of Interest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_5VlBfAsCCs"
      },
      "outputs": [],
      "source": [
        "def roi_filter(pcd, roi_min=(0,-3,-2), roi_max=(20,3,0)):\n",
        "    points = np.asarray(pcd.points)\n",
        "    mask_roi = np.logical_and.reduce((\n",
        "        points[:, 0] >= roi_min[0],\n",
        "        points[:, 0] <= roi_max[0],\n",
        "        points[:, 1] >= roi_min[1],\n",
        "        points[:, 1] <= roi_max[1],\n",
        "        points[:, 2] >= roi_min[2],\n",
        "        points[:, 2] <= roi_max[2]\n",
        "    ))\n",
        "    new_filtered_points=points[mask_roi]\n",
        "    # Create a new point cloud with the filtered points\n",
        "    roi_pcd = o3d.geometry.PointCloud()\n",
        "    roi_pcd.points = o3d.utility.Vector3dVector(new_filtered_points)\n",
        "    return roi_pcd\n",
        "roi_pcd = roi_filter(filtered_point_cloud)\n",
        "fig = vis_pcd([point_cloud.paint_uniform_color((0.2,0.2,0.2)),roi_pcd])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXVIkTc_t2dn"
      },
      "source": [
        "One of the key advantages is that the selected values depend on the car itself. This means that regardless of the situation, we'll always have the appropriate reflectance thresholding readily available. On the flip side, the downside is that it's a highly manual process.<p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czPygfBbAXxw"
      },
      "source": [
        "### **Lane Line Detection Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P92vN4oSAZUU"
      },
      "outputs": [],
      "source": [
        "def lane_line_pipeline(pcd):\n",
        "    filtered_point_cloud=reflectivity_threshold(pcd, thresh=0.5)\n",
        "    roi_pcd=roi_filter(filtered_point_cloud, roi_min=(0,-3,-2), roi_max=(20,3,0))\n",
        "    return roi_pcd, filtered_point_cloud, pcd\n",
        "\n",
        "point_cloud = o3d.io.read_point_cloud(point_cloud_files[idx])\n",
        "roi_pcd, filtered_point_cloud, pcd = lane_line_pipeline(point_cloud)\n",
        "\n",
        "fig = vis_pcd([pcd.paint_uniform_color((0.2,0.2,0.2)),roi_pcd], show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdIMD37YqsNm"
      },
      "source": [
        "**Video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir0BmOQwD7SI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_handle = cv2.VideoWriter(\"reflectance_output.avi\", cv2.VideoWriter_fourcc(*'DIVX'), 10, (2400, 1599))\n",
        "\n",
        "start_index = 350\n",
        "stop_index = 400\n",
        "pbar = tqdm(total = (stop_index - start_index), position=0, leave=True)\n",
        "all_files = [o3d.io.read_point_cloud(point_cloud_files[i]) for i in range(start_index, stop_index)]\n",
        "\n",
        "for i in range(len(all_files)):\n",
        "    roi_pcd, filtered_point_cloud, pcd = lane_line_pipeline(all_files[i])\n",
        "    fig = vis_pcd([pcd.paint_uniform_color((0.2,0.4,0.2)),roi_pcd], show=False, save=str(start_index+i))\n",
        "    output_handle.write(cv2.imread(\"output/\"+str(start_index+i)+\"_processed.jpg\"))\n",
        "    pbar.update(1)\n",
        "\n",
        "output_handle.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normals Estimation and filtering the objects by using Normals. We will distuinguish the lane lines and and the barricades on the road. For do that, we need the reuse our reflectivity_thereshold and roi_thereshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pcd = o3d.io.read_point_cloud(point_cloud_files[idx])\n",
        "filtered_point_cloud=reflectivity_threshold(pcd, thresh=0.45)\n",
        "roi_pcd=roi_filter(filtered_point_cloud, roi_min=(-20,-6,-2), roi_max=(20,6,0))\n",
        "roi_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=10,max_nn=30))\n",
        "o3d.visualization.draw_geometries([pcd.paint_uniform_color((0.8,0.8,0.8)),roi_pcd],point_show_normal=True)\n",
        "# Did you see the normal lines which has not a 90°. Let's eliminate them\n",
        "for i in range(100):\n",
        "    if i%10==0:\n",
        "        print(\"XYZ and normal for the point\",str(i))\n",
        "        print(roi_pcd.points[i])\n",
        "        print(roi_pcd.normals[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#def filtering_normals(pcd):\n",
        "normals=np.asarray(roi_pcd.normals)\n",
        "direction=np.array([0,0,1])\n",
        "angles=np.arccos(np.dot(normals,direction))\n",
        "angle_threshold=np.deg2rad(10)\n",
        "mask=np.where(np.abs(angles)<angle_threshold)[0]\n",
        "filtered_roi_pcd=roi_pcd.select_by_index(mask)\n",
        "o3d.visualization.draw_geometries([pcd.paint_uniform_color((0.8,0.8,0.8)),filtered_roi_pcd],point_show_normal=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKWjOByIFGcg"
      },
      "source": [
        "## Part II: 3D Object Detection\n",
        "So let's see a few algorithms to do this.\n",
        "1. Downsampling\n",
        "2. 3D Segmentation\n",
        "3. 3D Clustering\n",
        "4. Bounding Box Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONO_83_kygv_"
      },
      "source": [
        "### 1 — Downsampling\n",
        "Creating a video took time. It's not surprising since we're processing hundreds of thousands of points! But here's a thought: do we really need all those 100k+ points? What if we could achieve the same original shape with fewer points? That's where Downsampling comes into play."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJkah7Z0y1Ss"
      },
      "outputs": [],
      "source": [
        "pcd = o3d.io.read_point_cloud(point_cloud_files[200])\n",
        "print(len(pcd.points))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK6y7f8qyzlQ"
      },
      "outputs": [],
      "source": [
        "downpcd = pcd.voxel_down_sample(voxel_size=0.2)\n",
        "print(len(downpcd.points))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbFzC9V4zBV_"
      },
      "source": [
        "### 2 — 3D Segmentation\n",
        "Next, let's see how to use RANSAC (Random Simple Consensus) — an outlier detection algorithm, that can be used to fit a curve, a plane, or whatever we want. In OPEN3D, RANSAC is made this way:\n",
        "\n",
        "**plane_model, inliers = downpcd.segment_plane(distance_threshold=distance_threshold, ransac_n=ransac_n, num_iterations=num_iterations)**\n",
        "\n",
        "The parameters you can find in the Documentation of  [opend3d](http://www.open3d.org/docs/release/python_api/open3d.geometry.PointCloud.html?highlight=segment_plane)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v52G4O6Uy4FN"
      },
      "outputs": [],
      "source": [
        "def ransac(pcd, distance_threshold=0.33, ransac_n=3, num_iterations=100):\n",
        "    plane_model,inliers = pcd.segment_plane(distance_threshold=distance_threshold, ransac_n=ransac_n, num_iterations=num_iterations)\n",
        "    inlier_cloud = pcd.select_by_index(inliers)\n",
        "    outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
        "    outlier_cloud.paint_uniform_color([0.5, 0.75, 0.25])\n",
        "    inlier_cloud.paint_uniform_color([0.25, 0.5, 0.75])\n",
        "    return inlier_cloud, outlier_cloud\n",
        "\n",
        "inlier_cloud, outlier_cloud = ransac(downpcd, distance_threshold=0.33, ransac_n=3, num_iterations=150)\n",
        "fig = vis_pcd([inlier_cloud, outlier_cloud])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ransac with normals. THe normal estimation should improve the ransac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=10,max_nn=30))\n",
        "inlier_cloud, outlier_cloud = ransac(downpcd, distance_threshold=0.33, ransac_n=3, num_iterations=150)\n",
        "fig = vis_pcd([inlier_cloud, outlier_cloud])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfD9E2WzzUsJ"
      },
      "source": [
        "### Clustering (Object Detection)\n",
        "The next part is clustering. We have a set of \"outliers\" that contain our objects. Something natural could be to cluster these objects based on their distances. We can do that using KD-Tree algorithms, or the DBScan algorithm, built in Open3D.\n",
        "Here, the function will be:\n",
        "\n",
        "**outlier_cloud.cluster_dbscan(eps=eps, min_points=min_points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mym9ow77TqGO"
      },
      "outputs": [],
      "source": [
        "def dbscan(outlier_cloud, eps = 1, min_points=10,roi=False):\n",
        "    if roi:\n",
        "        outlier_cloud=roi_filter(outlier_cloud, roi_min=(-20,-8,-2), roi_max=(20,8,0))\n",
        "    labels = np.array(outlier_cloud.cluster_dbscan(eps=eps,min_points=min_points))\n",
        "    max_label=labels.max()\n",
        "    colors=plt.get_cmap(\"inferno_r\")(labels / (max_label if max_label > 0 else 1))\n",
        "    colors[labels < 0] = 0\n",
        "    outlier_cloud.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
        "    return outlier_cloud, labels\n",
        "\n",
        "roi_outliers, labels = dbscan(outlier_cloud, eps=2, min_points=100,roi=False)\n",
        "fig = vis_pcd([inlier_cloud, roi_outliers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQJApB2Le9EQ"
      },
      "outputs": [],
      "source": [
        "print(labels)\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XznKWo_3zmel"
      },
      "source": [
        "### 3D Bounding Boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8cgikvVfNy-"
      },
      "outputs": [],
      "source": [
        "def get_bounding_boxes(labels, outlier_cloud):\n",
        "    # Extract points for each cluster\n",
        "    clusters = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        if label >= 0:\n",
        "            if label not in clusters:\n",
        "                clusters[label] = []\n",
        "            clusters[label].append(outlier_cloud.points[i])\n",
        "\n",
        "    clusters = {label: points for label, points in clusters.items() if len(points) <= 300}\n",
        "\n",
        "    # Create AABB for each cluster\n",
        "    aabb_boxes = []\n",
        "    for points in clusters.values():\n",
        "        cluster_cloud = o3d.geometry.PointCloud()\n",
        "        cluster_cloud.points = o3d.utility.Vector3dVector(points)\n",
        "        aabb = cluster_cloud.get_axis_aligned_bounding_box()\n",
        "        aabb_boxes.append(aabb)\n",
        "    return aabb_boxes\n",
        "\n",
        "aabb_boxes = get_bounding_boxes(labels, roi_outliers)\n",
        "print(len(aabb_boxes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFCarKbvgAKb"
      },
      "outputs": [],
      "source": [
        "def get_trace(obb_boxes, fig):\n",
        "    width = 1.0\n",
        "    height = 2.0\n",
        "    depth = 3.0\n",
        "    for obb in obb_boxes:\n",
        "        # Get the eight corner points of the OBB\n",
        "        corners = np.asarray(obb.get_box_points())\n",
        "\n",
        "        # Extract x, y, and z coordinates of the corners\n",
        "        x = corners[:, 0]\n",
        "        y = corners[:, 1]\n",
        "        z = corners[:, 2]\n",
        "        # Create a Mesh3d trace for the oriented bounding box with opacity\n",
        "        obb_trace = go.Mesh3d(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            z=z,\n",
        "            i=[0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 2, 6, 4, 1, 3, 7, 5],\n",
        "            j=[1, 2, 3, 0, 5, 6, 7, 4, 2, 3, 7, 6, 1, 0, 4, 5, 6, 7, 3, 2, 0, 1, 5, 4],\n",
        "            k=[2, 3, 0, 1, 6, 7, 4, 5, 3, 7, 6, 2, 0, 4, 5, 1, 7, 6, 2, 4, 1, 5, 0, 3],\n",
        "            color='blue',\n",
        "            opacity=0.3\n",
        "        )\n",
        "\n",
        "        # Add the Mesh3d trace to the figure\n",
        "        fig.add_trace(obb_trace)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6eaXztCgtz2"
      },
      "outputs": [],
      "source": [
        "def pipeline(pcd):\n",
        "    inlier_cloud, outlier_cloud = ransac(pcd, distance_threshold=0.33, ransac_n=3, num_iterations=100)\n",
        "    roi_outliers, labels = dbscan(outlier_cloud)\n",
        "    aabb_boxes = get_bounding_boxes(labels, roi_outliers)\n",
        "    fig = vis_pcd([roi_outliers, inlier_cloud], show=False)\n",
        "    fig = get_trace(aabb_boxes, fig)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDQzfIdHhdtH"
      },
      "outputs": [],
      "source": [
        "pipeline(pcd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly0eS7pr9eC2"
      },
      "source": [
        "### Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kQ1tWlKllsB"
      },
      "outputs": [],
      "source": [
        "def seg_pipeline(pcd, idx):\n",
        "    downpcd = pcd.voxel_down_sample(voxel_size=0.2)\n",
        "    inlier_cloud, outlier_cloud = ransac(downpcd, distance_threshold=0.33, ransac_n=3, num_iterations=100)\n",
        "    roi_outliers, labels = dbscan(outlier_cloud)\n",
        "    aabb_boxes = get_bounding_boxes(labels, roi_outliers)\n",
        "    fig = vis_pcd([downpcd, roi_outliers, inlier_cloud], show=False)\n",
        "    fig = get_trace(aabb_boxes, fig)\n",
        "    fig.write_image(\"output/\"+str(idx)+\"_processed_obj.jpg\", scale=3)\n",
        "    fig = go.Figure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24D62-tkpYC-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_handle = cv2.VideoWriter(\"objects_output.avi\", cv2.VideoWriter_fourcc(*'XVID'), 10, (2400, 1599))\n",
        "\n",
        "start_index = 180\n",
        "stop_index = 230\n",
        "pbar = tqdm(total = (stop_index - start_index), position=0, leave=True)\n",
        "all_files = [o3d.io.read_point_cloud(point_cloud_files[i]) for i in range(start_index, stop_index)]\n",
        "\n",
        "for i in range(len(all_files)):\n",
        "    seg_pipeline(all_files[i], str(start_index+i))\n",
        "    output_handle.write(cv2.imread(\"output/\"+str(start_index+i)+\"_processed_obj.jpg\"))\n",
        "    pbar.update(1)\n",
        "\n",
        "output_handle.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "name": "PCDv2 Starter.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
